{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVD to Improve Recommendation Engines\n",
    "\n",
    "TODO:\n",
    "1. Write introduction\n",
    "2. Some bug in cosine similarity measure. \n",
    "\n",
    "__Source__: Simplifying Data with Singular Value Decomposition (Chapter 14) in Machine Learning in Action\n",
    "\n",
    "__Out of Scope__: Implementation of SVD. We'll use `linalg` in Numpy for factorization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "\n",
    "- TODO: Write an introduction in 2-3 lines\n",
    "\n",
    "\n",
    "Singular Value Decomposition (SVD) is a __matrix factorization__ algorithm which helps us distill distill hidden information from data. It finds application in number of fields ranging from bioinformatics to finance.  \n",
    "\n",
    "The idea of SVD is to represent the original data set with a compressed data set by removing noise and other redundant information. The latter is expected to hold just enough information which is needed for our algorithm to yield good results. Not only does the algorithm improve in terms of accuracy but improvement is also in terms of run time. However, as a downside, the transformed data is not so easy to comprehend. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Brief history of SVD\n",
    "SVD was first used in the field of information retrieval. _Latent Semantic Analysis (LSA)_ or _Latent Semantic Indexing (LSI)_  was the first algorithm to have used SVD. LSI is a method to search for words in a document. We construct a document-word matrix. However, a simple search of a word in a document misses the point that words may be mis-spelt or a synonym of the same word might have been used for the same concept. This is where SVD comes into play. SVD creates a set of _singular values_ which represents concepts or topics contained in the document. Now, instead of doing a vanilla search of words in the documents, we'll be searching in the concept space.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVD in Recommendation Systems\n",
    "Simple versions of recommendation systems compute similarity between users or items. However, advanced versions of the same use SVD to create a concept space from the data and then compute similarities between users/ items in this concept space. \n",
    "\n",
    "As an example, consider a matrix containing the ratings of 7 users for 5 restaurants. After applying SVD, let's assume we get a 2D concept space. This space broadly represents the dimensions along which user rating varied.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix Factorization\n",
    "As noted earlier, quite often only a few data points in a given dataset contains the relevant information. The other data points can be construed as noise or irrelevant. The data points of interest can be obtained by factorizing the original matrix. \n",
    "\n",
    "SVD takes an original matrix $Data$ of size $m*n$ and decomposes it into three matrices viz. $U, \\sum, V$ of dimensions $m*m$, $m*n$ and $n*n$ respectively. \n",
    "\n",
    "$$Data_{m*n} = U_{m*m} \\sum_{m*n} V_{n*n}^{T}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVD creates a $\\sum$ matrix which is a diagonal matrix. By convention, the diagonal elements in $\\sum$ are sorted in descending order. These diagonal elements are called singular values and they correspond to the singular values of our original dataset $Data$. \n",
    "\n",
    "#### Relation between singular values and eigen values\n",
    "PCA gives us the eigenvalues of a matrix which tells us the most important features in our dataset. The same thing is true about the singular values in $\\sum$. Singular values are the square root of the eigenvalues of $Data*Data^{T}$.\n",
    "\n",
    "#### Insignificant singular values\n",
    "Not all the singular values we'll obtain will be significant. Many of these will either be zero or negligibly small. We will see its relevance later in the code. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Practical points for SVD\n",
    "1. `linalg.svd` in Numpmy returns $\\sum$ as a row vector as it is a diagonal matrix. It is done with a view to saving space. \n",
    "2. _Heuristics for keeping optimal number of singular values_: Similar to PCA, keep 90% of the energy expressed by the $\\sum$ matrix. To calculate the total energy, add up all the squared singular values. Then add squared singular value until the sum reaches 90% of the total.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collaborative filtering based recommendation engines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. _Collaborative filtering_ based recommendation engines work by taking a data set of users' data and comparing it with the data of other users. Instead of trying to describe the similarity between items based on some attributes that an expert considers as important, we compare the similarity based on what people think of the items. In other words, collaborative filtering based approach doesn't care about the attributes of the items. It compares similarity strictly by the opinions of many users.  \n",
    "2. We can either compare the similarity between users or similarity between items. Later in this tutorial, we'll see why item based similarity makes more sense. \n",
    "\n",
    "We'll be seeing the folllwing things in this section:\n",
    "1. How to measure the similarity between items?\n",
    "2. Trade-offs between item based and user based similarity\n",
    "3. How to measure the success of a recommendation engine?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Similarity metrics\n",
    "1. __Based on Euclidean distance__: $similarity = 1/ (1+distance)$. If $distance=0$, $similarity = 1$. If $distance$ = large number, $similarity=0$.\n",
    "2. __Pearson correlation__: It is insensitive to the magnitude of the rating given by users. Value ranges from -1 to 1. It can be normalized so that it falls between 0 and 1 by using $0.5 + 0.5*corrcoef()$. \n",
    "3. __Cosine similarity__: Measures the cosine of the angle between two vectors. Ranges between -1 and 1. To be normalized in the same manner as explained in the previous point. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadExData():\n",
    "    return[[0, 0, 0, 2, 2],\n",
    "           [0, 0, 0, 3, 3],\n",
    "           [0, 0, 0, 1, 1],\n",
    "           [1, 1, 1, 0, 0],\n",
    "           [2, 2, 2, 0, 0],\n",
    "           [5, 5, 5, 0, 0],\n",
    "           [1, 1, 1, 0, 0]]\n",
    "\n",
    "def loadExData2():\n",
    "    return[[0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 5],\n",
    "           [0, 0, 0, 3, 0, 4, 0, 0, 0, 0, 3],\n",
    "           [0, 0, 0, 0, 4, 0, 0, 1, 0, 4, 0],\n",
    "           [3, 3, 4, 0, 0, 0, 0, 2, 2, 0, 0],\n",
    "           [5, 4, 5, 0, 0, 0, 0, 5, 5, 0, 0],\n",
    "           [0, 0, 0, 0, 5, 0, 1, 0, 0, 5, 0],\n",
    "           [4, 3, 4, 0, 0, 0, 0, 5, 5, 0, 1],\n",
    "           [0, 0, 0, 4, 0, 4, 0, 0, 0, 0, 4],\n",
    "           [0, 0, 0, 2, 0, 2, 5, 0, 0, 1, 2],\n",
    "           [0, 0, 0, 0, 5, 0, 0, 0, 0, 4, 0],\n",
    "           [1, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Note:__ In the similarity functions below, we will pass the input vectors as a column vector. This is with a view to using item based recommendation. The dataset to be used has users along the row and items along the column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import linalg as la\n",
    "\n",
    "def euclidean_similarity(inpA, inpB):\n",
    "    return 1.0/(1.0 + la.norm(inpA-inpB))\n",
    "\n",
    "def pearson_similarity(inpA, inpB):\n",
    "    if len(inpA) < 3: \n",
    "        return 1.0\n",
    "    else:\n",
    "        return 0.5 + 0.5*np.corrcoef(inpA, inpB, rowvar = 0)[0][1]\n",
    "    \n",
    "def cosine_similarity(inpA, inpB):\n",
    "    numerator = np.inner(inpA, inpB)  # float(inpA.T*inpB)\n",
    "    denominator = la.norm(inpA)*la.norm(inpB)\n",
    "    return 0.5 + 0.5*(numerator/denominator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'numpy.ndarray'>\n",
      "Test euclidean similarity 1.0\n",
      "Test pearson similarity 1.0\n",
      "Test cosine similarity 1.0\n"
     ]
    }
   ],
   "source": [
    "# Test similarity measures\n",
    "myMat = np.array(loadExData())\n",
    "print type(myMat)\n",
    "print \"Test euclidean similarity\", euclidean_similarity(myMat[:,0], myMat[:,0])\n",
    "print \"Test pearson similarity\", pearson_similarity(myMat[:,0], myMat[:,0])\n",
    "print \"Test cosine similarity\", cosine_similarity(myMat[:,0], myMat[:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating recommendation engines "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We use k-fold cross validation for this purpose. Note that in this case we don't know the target value to predict. Neither can we ask the user if our prediction is right. We will take some known rating and hold it out of the data. We'll then make a prediction for that value and compare it against the true value. \n",
    "- We will use RMSE to evaluate the recommendation engine. If the ratings are on a scale of 1 through 5, an RMSE of 1 would imply that our predictions are on an average one star off what the people actually think. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: Restaurant dish recommendation engine\n",
    "\n",
    "#### Problem statement\n",
    "To recommend restaurant and food item to users. \n",
    "\n",
    "#### Approach\n",
    "We'll first create a basic recommndation engine which looks for items a user hasn't tried. The next step is to improve the engine by using SVD to reduce the feature space.\n",
    "\n",
    "Given a user, it will return the top N best recommendations for that user. To do this we will do the following:\n",
    "1. Search for items the user in question hasn't yet rated i.e. look for 0's in the user-item matrix.\n",
    "2. For all the items this user hasn't yet rated, find a projected rating for each item i.e. predicted score for that item. This is where the similarity calculation comes into play. \n",
    "3. Sort the list in descending order and return the first N items. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def standEst(dataMat, user, simMeas, item):\n",
    "    \"\"\"\n",
    "    Description: Calculates the estimated rating a user would give to an item for a \n",
    "    given similarity measure.\n",
    "    input:\n",
    "    dataMat: user-item rating matrix. Users along the rows and items along the column. \n",
    "    user: User for whom items are to be predicted. \n",
    "    simMeas: Similarity metric to be used. \n",
    "    item: \n",
    "    \"\"\"\n",
    "    n = shape(dataMat)[1]  # Get number of items in the dataset\n",
    "    simTotal = 0.0; ratSimTotal = 0.0  # Variables to calculate estimated rating\n",
    "    for j in range(n):  # Loop over every item\n",
    "        userRating = dataMat[user,j]\n",
    "        # Skip the item which the user hasn't rated. Compare the items which are rated \n",
    "        # with other items which are rated. \n",
    "        if userRating == 0: \n",
    "            continue  \n",
    "        # The variable overlap captures the elements that have been rated between two\n",
    "        # items. If there's no overlap, the similarity is 0 and exit the loop. Otherwise,\n",
    "        # calculate the similarity based on overlapping items. \n",
    "        # overLap = nonzero(logical_and(dataMat[:,item]>0, dataMat[:,j]>0))[0]\n",
    "        overLap = nonzero(logical_and(dataMat[:,item].A>0, dataMat[:,j].A>0))[0]\n",
    "        if len(overLap) == 0: \n",
    "            similarity = 0\n",
    "        else: \n",
    "            similarity = simMeas(dataMat[overLap,item], dataMat[overLap,j])\n",
    "        print 'the %d and %d similarity is: %f' % (item, j, similarity)\n",
    "        simTotal += similarity\n",
    "        ratSimTotal += similarity * userRating\n",
    "    if simTotal == 0: \n",
    "        return 0\n",
    "    else:\n",
    "        # Normalize the similarity ratings product by dividing it by the sum of all the \n",
    "        # ratings. \n",
    "        return ratSimTotal/simTotal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend(dataMat, user, N=3, simMeas=cosine_similarity, estMethod=standEst):\n",
    "    \"\"\"\n",
    "    Generates the top N recommendations (N=3 by default). \n",
    "    \"\"\"\n",
    "    # Create a list of unrated items for a user\n",
    "    unratedItems = nonzero(dataMat[user,:].A==0)[1]\n",
    "    if len(unratedItems) == 0: \n",
    "        return 'User has rated all the items'\n",
    "    itemScores = []\n",
    "    # If there are unrated items, loop over each of those. For each unrated item, call\n",
    "    # the estimation method to get the forcasted score for that item. The item's index\n",
    "    # and the estimated score are placed in a list of tuples called itemScores. \n",
    "    # Finally, this list is sorted in descending order by the estimated score and \n",
    "    # returned. \n",
    "    for item in unratedItems:\n",
    "        estimatedScore = estMethod(dataMat, user, simMeas, item)\n",
    "        itemScores.append((item, estimatedScore))\n",
    "    return sorted(itemScores, key=lambda jj: jj[1], reverse=True)[:N]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4 4 0 2 2]\n",
      " [4 0 0 3 3]\n",
      " [4 0 0 1 1]\n",
      " [1 1 1 2 0]\n",
      " [2 2 2 0 0]\n",
      " [5 5 5 0 0]\n",
      " [1 1 1 0 0]]\n"
     ]
    }
   ],
   "source": [
    "# Test the functions in the last two blocks\n",
    "# Modify the matrix which was created earlier\n",
    "myMat = mat(loadExData())\n",
    "myMat[0,1] = myMat[0,0]= myMat[1,0]= myMat[2,0]= 4\n",
    "myMat[3,3] = 2\n",
    "print myMat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.matrixlib.defmatrix.matrix'>\n",
      "Recommendation for user 2"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "float argument required, not matrix",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-62-22a2bdd73739>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmyMat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mprint\u001b[0m \u001b[0;34m\"Recommendation for user 2\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecommend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmyMat\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-60-57734e735fec>\u001b[0m in \u001b[0;36mrecommend\u001b[0;34m(dataMat, user, N, simMeas, estMethod)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m# returned.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0munratedItems\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mestimatedScore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestMethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataMat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msimMeas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mitemScores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimatedScore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitemScores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mjj\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mjj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-59-2b975badf9c0>\u001b[0m in \u001b[0;36mstandEst\u001b[0;34m(dataMat, user, simMeas, item)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0msimilarity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msimMeas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataMat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moverLap\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataMat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moverLap\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0;32mprint\u001b[0m \u001b[0;34m'the %d and %d similarity is: %f'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msimilarity\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0msimTotal\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0msimilarity\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mratSimTotal\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0msimilarity\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0muserRating\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: float argument required, not matrix"
     ]
    }
   ],
   "source": [
    "print type(myMat)\n",
    "print \"Recommendation for user 2\", recommend(myMat,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Improving recommendations with SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svdEst(dataMat, user, simMeas, item):\n",
    "    n = shape(dataMat)[1]\n",
    "    simTotal = 0.0; ratSimTotal = 0.0\n",
    "    U,Sigma,VT = la.svd(dataMat)\n",
    "    Sig4 = mat(eye(4)*Sigma[:4]) #arrange Sig4 into a diagonal matrix\n",
    "    xformedItems = dataMat.T * U[:,:4] * Sig4.I  #create transformed items\n",
    "    for j in range(n):\n",
    "        userRating = dataMat[user,j]\n",
    "        if userRating == 0 or j==item: continue\n",
    "        similarity = simMeas(xformedItems[item,:].T,\\\n",
    "                             xformedItems[j,:].T)\n",
    "        print 'the %d and %d similarity is: %f' % (item, j, similarity)\n",
    "        simTotal += similarity\n",
    "        ratSimTotal += similarity * userRating\n",
    "    if simTotal == 0: return 0\n",
    "    else: return ratSimTotal/simTotal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "float argument required, not matrix",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-66-f679f301fffa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrecommend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmyMat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestMethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msvdEst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-60-57734e735fec>\u001b[0m in \u001b[0;36mrecommend\u001b[0;34m(dataMat, user, N, simMeas, estMethod)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m# returned.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0munratedItems\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mestimatedScore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestMethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataMat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msimMeas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mitemScores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimatedScore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitemScores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mjj\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mjj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-64-7ac884c0b41a>\u001b[0m in \u001b[0;36msvdEst\u001b[0;34m(dataMat, user, simMeas, item)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0muserRating\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0msimilarity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msimMeas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxformedItems\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m                             \u001b[0mxformedItems\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0;32mprint\u001b[0m \u001b[0;34m'the %d and %d similarity is: %f'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msimilarity\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0msimTotal\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0msimilarity\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mratSimTotal\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0msimilarity\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0muserRating\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: float argument required, not matrix"
     ]
    }
   ],
   "source": [
    "recommend(myMat, 1, estMethod=svdEst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the 1 and 0 similarity is: 0.626075\n",
      "the 1 and 3 similarity is: 0.672793\n",
      "the 1 and 4 similarity is: 0.614375\n",
      "the 2 and 0 similarity is: 0.429334\n",
      "the 2 and 3 similarity is: 0.387057\n",
      "the 2 and 4 similarity is: 0.043539\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(2, 3.4992661245386785), (1, 3.3272324280613659)]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommend(myMat, 1, simMeas= pearson_similarity, estMethod=svdEst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenges with building recommendation engines\n",
    "1. Doing SVD every time we want a projected score will make the system slow, particularly on the larger datasets. The SVD can be done once when the program is launched. On large systems, SVD is done once a day or is done offline. \n",
    "2. The user-ratings matrix will be sparse. We can save some memory and computation by storing only the non-zero values. \n",
    "3. In our program, we calculate the similarity score for multiple items each time we wanted a recommendation score. The scores are between items so we can reuse them if another user needs them. Another thing commonly done in practice is to compute the similarity score offline and store them. \n",
    "4. _Cold start problem_ refers to the problem of making recommendations when we have no data. We can make use of the attributes of the items in such cases.  In our example, we can tag the dishes with a number of parameters such as vegetarian, American BBQ, expensive and so on. We can treat these data for our similarity calculations. This is called content based recommendation. Such type is not as good as collaborative filtering based method, but it might be needed to take care of the cold start problem. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
